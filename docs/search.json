[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this site\n\n1 + 1\n\n[1] 2"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "",
    "text": "The training material provided is aimed at the novice with no experience of HPC or bioinformatics. You could be a biologist who wants to up their bioinformatics skills or a physical scientists (trained in computer science, maths or physics) interested in application your skills to the biological arena - this is where the journey starts.\nBig data is a fact of life for biologists whether they are reconstructing ecosystems from fragments of DNA (eDNA) found in the environment or reconstructing neural systems from MRI scans of brains - all walks of biology are exploiting larger and larger data sets. To access these data sets you will need a new set of skills - the time of big data biology is now.\nThere is a few piece of advice I would like to share before you get going on what I know will be a challenging but ultimately exciting and productive area of training:\n\nRTFM: Read The Fxxking Manual\n\nSorry for the expletives and starting my advice with an acronym but you will be using very complex software which will (mostly) generate some type of output - you need to know that output is valid and makes sense. By reading the manual and understanding concepts and theory behind what you are doing you will find it not only easier to use the software but also ensure that you results make sense. Most software comes with a ‘git hub page’, an online guide, a README file, help (accessed via the -h or -help flags) or a manual (man [command]). These resources have taken a huge amount of effort to generate - look through them, get to know the options, it will really help.\n\nBe part of the wider Bioinformatics community\n\nThere is a global bioinformatics community on-line and actively posting in chat rooms. Often the technical problem you are having or error code that has appeared has been seen before and you can find people have posted solution in old threads. You can post questions yourself and when you get more experienced find some time to contribute and help others.\nFrom chat rooms to human conversations with your colleague I have always gained more by contributing than trying to do things on my own. If you have time to develop your knowledge more formally I highly recommend lab exchanges or attending conferences or ‘hack-a-thons’ - it is fun to meet/learn from the people that develop the amazing code we use (and may be buy them beer to say thank you !!).\n\nGoogle is your friend\n\nNo I don’t have a preference in search engine (well maybe a little) - but weather your are looking for code, trouble shooting a problem or looking for new software a five minute web search can save you a high amount of time and/or reveal new exciting solutions/software. There are lots of tools on the internet that can help you with coding from utube videos to AI chat bots like Chatgpt. These are all part of the solution - find what works for you but always try and understand what you are doing.\n\nSolving problems is fun but do not forget the question\n\nThe coding and problem solving aspects of bioinformatics can be really seductive and fun (or frustrating and exasperating) and can drawn you in so all you are focused on is solving a gnarly problem with your code or writing a complex workflow. DO NOT FORGET the question you started with !!\nIt often helps to step back (I have a coffee) get some perspective - think about what you are trying to achieve, you could find a new way forward or find what you are doing is not need. Mostly the code is there of address a biological question - target your analysis to ensure it addressing the answers you seek.\nAny beyond all - have some fun doing science !!"
  },
  {
    "objectID": "index.html#basics-of-hpc-and-hpc-vs-personal-cloud-provision",
    "href": "index.html#basics-of-hpc-and-hpc-vs-personal-cloud-provision",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Basics of HPC and HPC vs Personal Cloud provision",
    "text": "Basics of HPC and HPC vs Personal Cloud provision\nThis element of the course introduces you the the computational resources that have been provided for you to perform the training. It also covers a light guide to login in to the research platforms at Cardiff School of Biosciences. If you are research at Cardiff wanting to gain access to HPC please contact our (Biocompute team)[http://hpc.bios.cf.ac.uk/contacts/] and join the bioinformatics teams community. If you are outside Cardiff - find out about your local HPC provision. If there is none locally look into cloud service such as AWS and Google …. many of these provide limited free options which can help you to learn."
  },
  {
    "objectID": "index.html#linux-the-basics",
    "href": "index.html#linux-the-basics",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Linux The basics",
    "text": "Linux The basics\nThis introduces you to the command line - yes no clicking on icons it is all about writing commands !!\nIntroduction Linux\nThis represent a rapid run through of the basics you need to get going on the commandline - lots of useful information and some basic exercises - copying / moving and learning about your linux environment this workshop is designed to get you start quickly.\nLinux the fundementals\nThis session places more detail about the linux basic covering navigating around your linux system (it has some graphical representations of your file system), auto-completion, file permissions and the fundamental anatomy of a linux command. We cover simple commands (copy/move ect), how to preview files (less/cat/head/tail) and how to edit file (we use Nano but look into Vi).\nCommandline Tools and Scripting\nFrom more ways to visualize text file, query file with grep, using editors, running scripts and loops this material provides some more exercises to develop your skills."
  },
  {
    "objectID": "index.html#an-introduction-to-ngs-data-and-quality-control",
    "href": "index.html#an-introduction-to-ngs-data-and-quality-control",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "An Introduction to NGS Data and Quality Control",
    "text": "An Introduction to NGS Data and Quality Control\nMost of our training material does focus on bioinformatics application in the area of genomics. The section introduces the fundamental concepts of Next Generation Sequencing (NGS) and the basic file types (fasta / fastq) and approaches to quality control (evaluation) and initial data processing."
  },
  {
    "objectID": "index.html#genome-assembly",
    "href": "index.html#genome-assembly",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Genome Assembly",
    "text": "Genome Assembly\nApproaches to Genome assembly vary hugely depending on what your are assembling and what type of data you have available to you. This course introduces the fundamental concepts of assembly and how you evaluate the quality of your assemblies. It provides examples and approaches that are good for small genomes - like organelles (15-200 kb) and bacterial genomes (1-5 Mb). The primary examples use short read (Illumina) have be customised to exploit long read (Nanopore / Pacbio) or combinations and short and long read data."
  },
  {
    "objectID": "index.html#genome-annotation-and-visualisation",
    "href": "index.html#genome-annotation-and-visualisation",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Genome Annotation and Visualisation",
    "text": "Genome Annotation and Visualisation\nA genome or transcript assembly means little until you overlay it with biological information. Here we introduce to to both generate that biological information as well as visualize the results. We primarily use Artemis (Sanger centre) but also introduce Integrated Genome Viewer (IGV) from the (Broad Institute)"
  },
  {
    "objectID": "index.html#phylogenomics-and-phylogenomics",
    "href": "index.html#phylogenomics-and-phylogenomics",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Phylogenomics and Phylogenomics",
    "text": "Phylogenomics and Phylogenomics\nThe taxonomic relationships between organisms can be derived through the genetic differences between them. This workshop provides a refresher of the basic principles and then provides examples of how to derive phylogenetic trees from single gene trees to whole genomes. Ultimately, the more global the information used to generate a phylogeny the more resolution / understanding you have about the relationship between organism at the level of the population or individual."
  },
  {
    "objectID": "index.html#transcriptomics",
    "href": "index.html#transcriptomics",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Transcriptomics",
    "text": "Transcriptomics\nThe has been divided into three workshops each targeted at different aspects of the process.\nRNAseq Data Processing\nTranscriptomics is all about counting - this workshop cover how we get from raw RNAseq reads to counts given and known and annotated genome. We include approaches to identify and evaluate technical duplication - be aware this may not be relevant to your analytical approach.\nGeneration of Differnential Gene DEG Lists\nPerforming quality control and provisional data visualization (Volcano plots and MA) are all essential steps on before generating differential gene lists. Here we use SARTools developed at the pasteur institute to illustrate best practice in transcriptome analysis. We also include multi-variant approach to data visualization such as PCA and HCA (Hierarchical clustering)\nFunctional Interpreation of DEGs\nInterpreting the biological significant of a list of gene IDs or gene symbols representing your DEGs can be a significant but fun challenge. This course shows selection of tools that allow you to go from DEG to functional networks."
  },
  {
    "objectID": "index.html#metabarcoding",
    "href": "index.html#metabarcoding",
    "title": "Key skills for Big Data Biology and Bioinformatics",
    "section": "Metabarcoding",
    "text": "Metabarcoding\nAmplification of short phylogenetically informative sections of DNA can be used to generate community profiles. This course introduces the concepts of metabarcoding the targets that are used for different phylogenetic groups (16S - bacterial, ITS - fungal, RbcL -Algal and COI/18S Eukaryotic). Data analysis uses (Qiime2)[https://qiime2.org/] to navigate you through preliminary metabarcoding data analsyis."
  },
  {
    "objectID": "Personal_Cloud.html",
    "href": "Personal_Cloud.html",
    "title": "Personal Cloud",
    "section": "",
    "text": "To access any Cardiff University HPC or personal Cloud resources you will need to install and login to the University VPN - see Instructions below\nHPC systems are large multi-processor large RAM ‘computer’ that are installed in data centres. usually users are provided with a log-in to a shared HPC-system with strictly control access writes and defined quotas. To run your informatic tasks you would configure a script to send your job to a ‘queuing’ program that coordinates the processing request of all the users on the system. In this way the system can support large numbers of users but you need to wait for your place in the ‘queue’ for your task to be performed. Although you can do simple task - manipulate files (copy, rename ect) without sending a queue script most tasked you would need to configure your queue script and send to the job to the queue - this can be very tedious when learning’s to code since even script with error would need to wait for the request to be queued.\nTo avoid the ‘queues’ we provide person cloud systems to each person on the course allowing the to interactively interact with the HPC system. To do this we create a container which contains the equivalent of a ‘virtual machine’ (VM) in the cloud, we use a system called kubernetes to create these container based virtual machines, where each user has dedicated processor, RAM, storage and their own environment so they can interactively learn to use a linux system. Because we are having to reserve a proportion of the server for each user we can only allocate a limited number of processor and RAM to each user - usually this is 8 Processor and 16 Gb RAM but check with you course organiser.\nSimilar ‘containers’ can be accessed using AWS cloud services (https://aws.amazon.com/health/genomics/) or through academic services such as CLIMB (https://www.climb.ac.uk/). AWS cloud does provide some educational free cloud processing but when these free credits are over you would need to pay for processing and storage - this can very quickly get expensive. CLIMB always academic registration if you are supported by specific research council funding."
  },
  {
    "objectID": "Personal_Cloud.html#kubernete-vm",
    "href": "Personal_Cloud.html#kubernete-vm",
    "title": "Personal Cloud",
    "section": "kubernete VM",
    "text": "kubernete VM\nYou will be provided with three pieces of information the host (or server) name, your user name (usually your staff ID or your student ID including the the ‘small letter’ prefix), a port number and a randomly generated pass phase. Here are some examples (user names and pas phases are fictitious).\nHost Name: hawker.bios.cf.ac.uk sponsa.bios.cf.ac.uk\nUsername (student numbers usually have a small letter and 7 digits): c9999999 or sbixxx\nPort (5 digit number): 32222\nPassword: hard_phase_remember\nYou may have received an email where the information is presented as a code block:\nssh c9999999@hawker.bios.cf.ac.uk -P 32222\n       ^              ^                ^\n    username        host              port"
  },
  {
    "objectID": "Personal_Cloud.html#hpc-cluster-access",
    "href": "Personal_Cloud.html#hpc-cluster-access",
    "title": "Personal Cloud",
    "section": "HPC cluster access",
    "text": "HPC cluster access\nIf you are provided with access either teaching or research HPC systems you will only be provided with a host or server name - you username and password will be your Single Sign-On (SO) for the University - your student/staff number and your standard password.\nserver currently used include:\nHost Name: hawker.bios.cf.ac.uk sponsa.bios.cf.ac.uk\nWith standard HPC teh port number is always 22"
  }
]