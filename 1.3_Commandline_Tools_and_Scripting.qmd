---
title-block-style: default
title-block-banner: darkred
title-block-banner-color: white
title: "Extension: Commandline Tools and Scripting"
subtitle: "Loads more tricks and tips"
author: "Professor Peter Kille"
date: today
affiliation: "Cardiff University"
---

```{r include=FALSE}
knitr::opts_chunk$set(eval = FALSE)
```

# Visualising Text Files

There are many commands available for reading text files on Linux/Unix. These are useful when you want to look at the contents of a file, but not edit them. Among the most common of these commands are `cat`, `more`, `less`, `head` and `tail`.

`cat` can be used for concatenating files and reading files into other programs; it is a very useful facility. However, `cat` streams the entire contents of a file to your terminal and is thus not that useful for reading long files, as the text streams past too quickly to read.

`more` and `less` are commands that show the contents of a file one page at a time, but `less` has more functionality than `more` (doh)! With both `more` and `less`, you can use the space bar to scroll down the page, and typing the letter q causes the program to quit -- returning you to your command line prompt.

`head` and `tail` show the first and last ten lines of a document, respectively. You can use the argument -n \[number\] to change the number of lines displayed.

Once you are reading a document with `more` or `less`, typing a forward slash / will start a prompt at the bottom of the page, and you can then type in text that is searched for below the point in the document you were at. Typing in a ? also searches for a text string you enter, but it searches in the document above the point you were at. Hitting the n key during a search looks for the next instance of that text in the file.

With `less` (but not `more`), you can use the arrow keys to scroll up and down the page, and the b key to move back up the document if you wish to.

Remember these are just for reading the files. If you want to edit them you'll need a text editor like nano or vi.

::: callout-important
## Exercise

Move into an appropriate working directory in mydata

Fetch the file O97435.embl using `wget` (this is just a command for downloading files from the web).

```{bash}
wget https://rest.uniprot.org/uniprotkb/O97435.txt > O97435.embl
```

using the commands `cat`, `more`, `less`, `head` and `tail`.

Don't forget that tab completion can save you typing effort!

```{bash}
cat O97435.embl
more O97435.embl # Use the spacebar to scroll down
Press q to quit.
```

Now try `less`

```{bash}
less O97435.embl
```

Use the spacebar to scroll down, b to go up a page, and the up and down arrow keys to move up and down the file line by line.

Press the / key and search for the letters sequence in the file. Press the ? key and search for the letters gene in the file.

Press the n key to search for other instances of gene in the file.

```{bash}
head O97435.embl
tail O97435.embl
```

For reading files yourself, we recommend the command `less.` The command `cat` is more usually used in conjunction with other commands when you wish to process text from within a file in some way.

Remember the man pages

There are many command line options available for each of the above commands, as well as functionality we do not cover here. To read more about them, consult the manual pages:

```{bash}
man cat
man more
man less
man head
man tail
```
:::

# Querying files with grep

grep stands for global regular expression print; you use this command to search for text patterns in a file (or any stream of text). eg.

```{bash}
grep “adge” /usr/share/dict/words
```

You can also use flexible search terms, known as regular expressions, in your grep searches. You have already used glob pattern expressions in this practical, but regular expressions are somewhat different and more powerful. For example, when you listed all files with the pattern tes*embl* you were using a glob pattern comprising explicit characters (e.g. tes) and special symbols (\* meaning any character or characters). The equivalent in grep would be "tes.*embl.*" where the period signifies any single character and the \* signifies any number of repeats.

Therefore to get from a shell glob pattern to a regular expression replace each \* with .\* and each ? with . . You also need to enclose the expression in quotes to tell the shell not to try and interpret it as a glob.

Unmodified glob patterns will be accepted by grep but will not work as intended. For example the pattern tes\* in grep means te followed by any number of s characters in sequence (te, tes, tess, tesss, ...). The question mark now signifies optionality -- so tes? means te followed by zero or one s character (te, tes). Regular expressions are found in several places other than grep, most notably in the Perl scripting language. The full syntax is extensive and powerful but is beyond the scope of this course, so back to the command itself...

grep requires a regular expression as input, and returns all the lines containing that pattern to you as output.

grep is especially useful in combination with pipes as you can filter the results of other commands.

For example, perhaps you only want to see only the information in an EMBL file relating to the origin of the sequence, that is, the DE line. You do not need to search the file in an editor, you can just grep for lines beginning in DE, as in the next exercise.

::: callout-important
## Exercise

Move into an appropriate working directory in `mydata`

Fetch the file O97435.embl using `wget`

```{bash}
wget https://rest.uniprot.org/uniprotkb/O97435.txt > O97435.embl
```

While in the download directory, type the command:

```{bash}
grep “DE” O97435.embl 
```

What is this command doing?

Can you see why the above command results in the output you see? An explanation of this command can be found below this exercise box.

Try the commands:

```{bash}
grep “^DE” O97435.embl
grep -x “DE.*” O97435.embl 
```

What are the \^ symbol and the -x parameter in these commands doing? Check the manpage for grep to be sure.

Try the command:

```{bash}
cat O97435.embl | grep “^DE”. 
```

Does that do what you expected?

Use the above command with a pipe and a grep command to search for files created or modified today.

The first command in the above exercise searches all the text in the O97435.embl file and returns the lines in which it finds the letter D followed by the letter E.

The second command in the exercise also returns lines in the file that have a letter D followed by a letter E, but only where DE is found at the beginning of a line. This is because the \^ symbol means "match at the beginning of a line". The \$ symbol can be used similarly to mean "at the end of a line". These are known as anchors. Passing the -x flag to grep tells it to automatically anchor both ends of the search pattern.

What this anchoring does in the example above is return to you just the organism information in the embl file. This is because none of the other lines returned in the previous command started with DE, they just contained DE somewhere in them. This is an example where knowing how information is stored in an given file, along with a few basic Linux commands, allows you to retrieve information quickly.

Another common example is counting how many sequences are in a set of multi-fasta files. We can do this with pipes between the commands `cat`, `grep` and the handy `wc` (word count) utility, which here we use to count lines found by grep.

```{bash}
cat *seqs.fasta | grep “^>” | wc -l 

grep -c “^>” *seqs.fasta 
```

Each sequence in a fasta file starts with a header line that begins with a \> . The above command streams the contents of all files matching the glob pattern \*seqs.fasta through a search with grep looking for lines that start with the symbol \> . The quotes around the pattern \^\> are necessary, as otherwise it is interpreted as a request for redirection of output to a file, rather than as a character to look for. As before, the \^ symbol means "match only at the beginning of the line".

The output of this grep search is sent to the `wc` command, with the -l indicating that you want to know the number of lines -- ie. the number of headers and by implication the number of sequences.

An easier version of this shown as the second example uses the `grep` -c argument that return the number of matches found.

So a synopsis of the command above is: Read through all files with names ending seqs.fasta and look for all the header lines in the combined output, then count up those lines that matched and return the number to screen.
:::

## Use zgrep with compressed files

You can use all of grep functionality with a compressed file by adding a 'z' - just replace grep with zgrep and you can directly query that .gz files.

# Using text editors

Plain text files are important, both as input to bioinformatics programs and as input or configuration files for system programs. We highly recommend that you learn to use a text editor to prepare and edit plain text files.

## Text files, Word Processors and Bioinformatics

Documents written using a word processor such as Microsoft Word or OpenOffice Write are not plain text documents. If your filename has an extension such as .doc or .odt, it is unlikely to be a plain text document. (Try opening a Word document in notepad or another text editor on Windows if you want proof of this.)

Word processors are very useful for preparing documents, but we recommend you do not use them for working with bioinformatics-related files.

We recommend that you prepare text files for bioinformatics analyses using Linux-based text editors and not Windows- or Mac-based text editors. This is because Windows- or Mac-based text editors may insert hidden characters that are not handled properly by Linux-based programs.

There are a number of different text editors available on Bio-Linux. These range in ease of use, and each has its pros and cons. In this practical we will briefly look at two editors, ***nano and vi***. \## Nano

***Pros:***

very easy -- For example, command options are visible at the bottom of the window can be used when logged in without graphical support fast to start up and use

***Cons:***

by default it puts return characters into lines too long for the screen (i.e. using nano for system administration can be dangerous!) This behavior can be changed by setting different defaults for the program or running it with the --w option. It is not completely intuitive for people who are used to graphical word processors

## Vi (or Vim)

***Pros:***

Appears on nearly every Unix system. Can be very powerful if you take the time to know the key-short cuts.

***Cons:***

You have to know the shortcuts!! There's no menus and no on screen prompts

::: callout-important
## Exercise

### Create a file with nano

```{bash}
nano test_nano.txt 
```

type some text, exit ctrl X, save and return to command line now list the contents of the file you created

```{bash}
less test_nano.txt 
```

### Create a file with vi

```         
vi test_vi.txt 
```

type 'a' and you can then add text

exit saving you edits \[esc\]:wq! - this stands for write quit !!

now list the contents of the file you created

```{bash}
less test_vi.txt 
```
:::

# Running and rerunning scripts

Bioinformatic is full of altruistic people who share their skills by share their scripts. Most scripts you find on the internet are written in \perl (\bioperl) or \python (\biophython). There are a few simple steps to making use of this fantastic resource.

## Step 1: Create your Script

Make a text file containing the script in question. This can be achieved by downloading or transferring the scripts as a file in the correct format. Sometimes the scripts are posted as part of a website such as a web-post in a discussion forum. To use these scripts, create a file using vi or nano and copy into the test file the script in question ensuring you save it with an appropriate name.

Here's a script you can try

```{bash}
#!/bin/bash 

echo {10..1} 

echo 'Blast off' 
```

## Step 2: Make your script executable

Make the file executable. Before you can run the script you must make it executable. This is done by changing its property using

```{bash}
chmod a+x [script name] 
```

this is shorthand for chmod (change modify) a(all)+(add)execute(e) \[script name\] -- thus changing the permission to allow everyone to execute a script. For more guide to chmod see https://en.wikipedia.org/wiki/Chmod

## Step 3: Run Your Script

Run the program. This should be easy but there are a few ways of doing this.

Place the program into the directory where you want to use it and type

```{bash}
./[script name] parameters arguments 
```

On first use try to run with no parameters or arguments or with -h and -help to see the manual for the script. Some poorly written scripts will need you to define the program you need to use them. Ie if it was a perl program (you may have to module load perl before you run this example).

```{bash}
perl [script name] parameters arguments 
```

Run from scripts current location using full path.

```{bash}
/full path/[script name] parameters arguments 
```

Place the script into your 'PATH' -- this means that the computer automatically knows about the script and will run it from any location just given the program name. I suggest that if you want to do this ask the demonstrators and they can show you......this is advanced as if you put two scripts with the same name into the PATH you can cause issues.

# For...Done Loops -- When Processing Lots of Data

## Loops using numerical variables

Creating a Loop

Invoke a text editor such as nano, then type

```{bash}
#!/bin/bash

for i in {1..[number]}; do 

# use hash to include some level of documentation so when you get to script in a few months time 

# you can remember what it was all about.  ${i} = number which increment by 1 each time the loop runs

[your commands]${i} 

done
```

save.

now make the program executable

```{bash}
chmod +x [program_name]
```

run

```{bash}
./[program_name]
```

## Loops using Strings (lists) as variables

Invoke a text editor such as nano, then type

```{bash}
#!/bin/bash

for i in sampleA sampleB sampleC sampleD; do 

# use hash to include some level of documentation so when you get to script in a few months time

# you can remember what it was all about.  ${i} = the list of strings given at the start of the for loop 

[your commands]${i} 

done 
```

save

now make the program executable

```{bash}
chmod +x [program_name] 
```

run

```{bash}
./[program_name] 
```

## Loops using directory listings

This is a great method if you want to execute a series of command on a set of data files contained in a specific directory, for instance a series of sequence files.

Invoke a text editor such as nano, then type

```{bash}
#!/bin/bash

sequence_dir=[location of folder containing paired end sequence files]
#*_R1.fastq - lists all files ending in _R1.fastq

for f in ${sequence_dir}/*_R1.fastq
do

#the file name are placed in variable $f - we can separate the name of the file away from the suffix (.fastq) using this simple cut expression - the variable 'R1' now contains the file name with no suffix 
R1=$(basename $f | cut -f1 -d.)

#Sometimes we want the 'base' name of the file without the direction suffix (_R1) - this expression creates a variable 'base' where the _R1 has been replace is nothing - ie removed 
base=$(echo $R1 | sed 's/_R1//')

echo ${base}

done 
```

save

now make the program executable

```{bash}
chmod +x [program_name] 
```

run

```{bash}
./[program_name] 
```

# Decompressing tar.gz and .gz files

You will commonly come across 2 type of compressed files in Linux .gz and tar.gz. The gz are equivalent to a 'zip' file in windows, whilst a tar.gz represent a compressed archive - that means it will contain multiple files and folders. Here's how to handle these file:

## gz files

....wait a minute do you really need to decompress this file !! Many programs will happily use a .gz file directly, this a win for your file space so check out if you really need to decompress the file. Unfortunate some utilits like 'sed' require files to be unzipped, it that case:

```{bash}
#to decompress
gunzip [filename].gz
#to recompress
gzip [filename]
```

## How to extract a .tar.gz file on Linux

To extract a .tar.gz file on Linux, you can use the "tar" command in the terminal. Here is the general syntax:

```{bash}
tar -xvzf filename.tar.gz
```

Here is a brief explanation of the options used:

```{bash}
-x: This option tells tar to extract the contents of the archive.

-v: This option is for verbose output, which means that tar will display a list of the files being extracted as it does so.

-z: This option tells tar to decompress the archive using gzip.

-f: This option is used to specify the archive file to extract.
```
